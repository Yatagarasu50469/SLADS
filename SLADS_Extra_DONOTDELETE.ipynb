{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "manualMasks = []\n",
    "dataFileNames = glob.glob(\"./manualSegmentation\" + \"/*\" + ImageExtension) #Obtain filenames for each set\n",
    "for j in range(0,numberTestFiles):  \n",
    "    name = re.sub(testingDataImagesPath, '', dataFileNames[0])\n",
    "    name = re.sub('originalSegmentation','manualSegmentation',name)\n",
    "    manualMasks.append(Image.open(name).convert('L'))\n",
    "    \n",
    "\n",
    "    \n",
    "    #Extract the information needed to grab the manual version\n",
    "\n",
    "\n",
    "mseMasks = []\n",
    "ssimMasks = []\n",
    "for i in range(0, len(StopPercentageTestingSLADSArr)):\n",
    "    mseMask = []\n",
    "    ssimMask = []\n",
    "    for j in range(0,numberTestFiles):\n",
    "        testImageFileName = dataFileNames[j]       \n",
    "        reconstructionMask = np.asarray(all_reconstructionMasks[i][j])[0]\n",
    "        reconstructionMask = Image.fromarray(test*255)\n",
    "        manualMask = manualMasks[j]\n",
    "        \n",
    "        mseMaskValue = #Calculate MSE\n",
    "        ssimMaskValue = #Calculate SSIM\n",
    "        mseMask.append(mseMaskValue)\n",
    "        ssimMask.append(ssimMaskValue)\n",
    "    mseMasks.append(mseMask)\n",
    "    ssimMasks.append(ssimMask)\n",
    "\n",
    "#Make plot of MSE, each percentage as series\n",
    "\n",
    "\n",
    "\n",
    "#Make plot of SSIM, each percentage as series    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTER ERDVALUESNP BY RECONIMAGE CONTOUR RESULTS; FINDNEWMEASUREMENTIDXS FUNCTION\n",
    "#NOTE THAT ERDVALUESNP IS DERIVED FROM THE RECONIMAGE, SO UNLESS SOMETHING HAS GONE WRONG, THIS SHOULDN'T BE NECCESSARY\n",
    "\n",
    "            \n",
    "            #Find the largest area in recon image; filter ERDValuesNP with it (nan for absent)\n",
    "            #filterArray = np.empty([SizeImage[0],SizeImage[1]])\n",
    "            #filterArray[:] = np.nan\n",
    "            #contours, hierarchy = cv2.findContours(ReconImage.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) #Identify areas\n",
    "            #areas = [cv2.contourArea(c) for c in contours] #Save the areas into an object\n",
    "            #filterArray = cv2.drawContours(filterArray, [contours[np.argmax(areas)]], -1, (255, 255, 255), -1) > 0 #Draw largest area\n",
    "            #filteridxs = np.argwhere(filterArray).tolist()\n",
    "            #xValues = tuple([x[0] for x in filteridxs])\n",
    "            #yValues = tuple([y[1] for y in filteridxs])\n",
    "            #filteredERDValuesNP = np.empty([SizeImage[0],SizeImage[1]])\n",
    "            #filteredERDValuesNP[:] = np.nan\n",
    "            #filteredERDValuesNP[xValues, yValues] = ERDValuesNP[xValues, yValues]\n",
    "            \n",
    "            #Choose the line with most information gain, both with and without filtering by area\n",
    "            #lineERDValues = []\n",
    "            #lineERDValuesFiltered = []\n",
    "            #for line in InitialMaskObject.linesToScan:\n",
    "            #    xValues = tuple([x[0] for x in line])\n",
    "            #    yValues = tuple([y[1] for y in line])\n",
    "            #    if InitialMaskObject.useERDmean:\n",
    "            #        lineERDValues.append(np.nanmean(ERDValuesNP[xValues, yValues]))\n",
    "            #        lineERDValuesFiltered.append(np.nanmean(filteredERDValuesNP[xValues, yValues]))\n",
    "            #    else:\n",
    "            #        lineERDValues.append(np.nansum(ERDValuesNP[xValues, yValues]))\n",
    "            #        lineERDValuesFiltered.append(np.nansum(filteredERDValuesNP[xValues, yValues]))\n",
    "\n",
    "            #if InitialMaskObject.partialLine:\n",
    "            #    idxs = InitialMaskObject.linesToScan[np.nanargmax(lineERDValuesFiltered)]\n",
    "            #    for idx in idxs:\n",
    "            #        if not np.isnan(filteredERDValuesNP[tuple(idx)]): \n",
    "            #            NewIdxs.append(idx)\n",
    "            #else:\n",
    "            #    NewIdxs = InitialMaskObject.linesToScan[np.nanargmax(lineERDValues)]\n",
    "\n",
    "            #If this procedure yields no new pixels to scan fall back on full line scanning\n",
    "            #if len(NewIdxs) <= 0:\n",
    "            #    NewIdxs = InitialMaskObject.linesToScan[np.nanargmax(lineERDValues)]\n",
    "            \n",
    "            \n",
    "            \n",
    "#PARALLIZE NEW IDX FINDING WITHIN THE FINDNEWMEASUREMENTIDXS FUNCTION\n",
    "#THIS WAS FOUND TO SIGNFICANTLY DECREASE PROGRAM EFFICIENCY (17 SECONDS) AND WAS REMOVED\n",
    "\n",
    "def idxFinder_parhelper(InitialMaskObject, ERDValuesNP, testResult, lineToScan, lineNum):\n",
    "    line = InitialMaskObject.linesToScan[lineNum]\n",
    "    ERDPtsToScan = []\n",
    "    sumLineERDValue = np.nan\n",
    "    ptsList = []\n",
    "    for pt in line:\n",
    "        if pt in lineToScan:\n",
    "            ERDPtsToScan.append(pt)\n",
    "        if testResult[tuple(pt)]:\n",
    "            if np.isnan(sumLineERDValue):\n",
    "                sumLineERDValue = ERDValuesNP[tuple(pt)]\n",
    "            else:\n",
    "                sumLineERDValue = sumLineERDValue + ERDValuesNP[tuple(pt)]\n",
    "            ptsList.append(pt)\n",
    "    return ERDPtsToScan, sumLineERDValue, ptsList\n",
    "\n",
    "#OLD TESTING ROUTINE, REPEATED CALCULATION EFFFORT, NO ANIMATION INTEGRATION, USED ARRAY OF POSSIBLE STOPPING PERCENTAGES\n",
    "#OLD TESTING ROUTINE\n",
    "    \n",
    "    #For each of the possible training sampling percentages (each with their own best c)\n",
    "    for p in tqdm(range(0,len(StopPercentageSLADSArr)), desc = 'Training Sampling Percentages', leave = True):\n",
    "        StopPercentageSLADS = float(StopPercentageSLADSArr[p])\n",
    "        \n",
    "        #Import the best c and theta values; Training for database must have been performed first\n",
    "        if not overrideBestC: #If automatic best c selection\n",
    "            LoadPath_bestc = trainingFeaturesPath + 'TrainingDB_' + str(TestingImageSet) + os.path.sep + 'best_c' + '_StopPerc_' + str(StopPercentageSLADS) + '.npy'\n",
    "            if not os.path.exists(LoadPath_bestc):\n",
    "                sys.exit('Error!!! The best c file ' + SavePath_bestc + ' does not exist. Check entry for ' + SavePath_bestc)\n",
    "            c = np.load(LoadPath_bestc)[0].astype(float)\n",
    "        else: #If manual best c selection\n",
    "            c = overrideBestCValue.astype(float)\n",
    "\n",
    "        #Directory setup for Theta\n",
    "        ThetaLoadPath = trainingFeaturesPath + TrainingDBName + os.path.sep + 'c_' + str(c) + os.path.sep\n",
    "        if not os.path.exists(ThetaLoadPath):                                                                                                                          \n",
    "            sys.exit('Error!!! Check folder ./ResultsAndData/TrainingSavedFeatures/TrainingDB_' + TrainingImageSet + ' for folder c_' + str(c))\n",
    "        \n",
    "        #Load Theta\n",
    "        Theta=np.transpose(np.load(ThetaLoadPath +'Theta' + '_StopPerc_' + str(StopPercentageSLADS) + '.npy'))\n",
    "\n",
    "        Beta = computeBeta(SizeImage)\n",
    "        StopCondParamsObject=StopCondParams()\n",
    "        \n",
    "        #Create an object to hold progressive development of model\n",
    "        testingResultsAverageObject = simulationResults() \n",
    "        testingResultsAverageObject.initialize()\n",
    "        \n",
    "        #Create an object to hold all of the testing results for each sampling percentage\n",
    "        testingResults = []\n",
    "        \n",
    "        all_MSE_testingResults = []\n",
    "        all_SSIM_testingResults = []\n",
    "        all_Distort_testingResults = []\n",
    "        all_reconstructionMasks = []\n",
    "        \n",
    "        #For each of the possible testing sampling percentages\n",
    "        for q in tqdm(range(0,len(StopPercentageTestingSLADSArr)), desc = 'Testing Sampling Percentages', leave = True):\n",
    "            StopPercentageTestingSLADS = float(StopPercentageTestingSLADSArr[q])\n",
    "            StopCondParamsObject.initialize(Beta,StoppingThrehsold,50,2,StopPercentageTestingSLADS)\n",
    "            dataFileNames = glob.glob(testingDataImagesPath + \"/*\" + ImageExtension) #Obtain filenames for each set\n",
    "            numberTestFiles = len(testingData)\n",
    "\n",
    "            #Perform SLADS on all of the images, saving statistics of interest in parallel\n",
    "            testingResultObject = Parallel(n_jobs=num_threads)(delayed(stats_parhelper)(num_threads, InitialMaskObject, loadOrGenerateInitialMask(loadPathInitialMask,MaskType,InitialMaskObject,SizeImage,lineScanning), codePath, TestingImageSet, SizeImage, StopCondParamsObject, Theta, TrainingInfoObject, TestingInfoObject, Resolution, ImageType, UpdateERDParamsObject, BatchSamplingParamsObject, testingOutputName(testingFeaturesPath, dataFileNames[i], StopPercentageSLADS, StopPercentageTestingSLADS), i, ImageExtension, PlotResult, Classify, errorPlot, isRunningParallel, lineScanning, simulation, testingData[i]) for i in tqdm(range(0,numberTestFiles), desc = 'Testing Images', leave = True))\n",
    "            \n",
    "            #Create holding arrays for the results\n",
    "            MSE_testingResults = []\n",
    "            SSIM_testingResults = []\n",
    "            Distort_testingResults = []\n",
    "            reconstructionMasks = []\n",
    "            \n",
    "            #Extract results from returned object\n",
    "            for result in testingResultObject: \n",
    "                MSE_testingResults.append(result.mseError)\n",
    "                SSIM_testingResults.append(result.ssimError)\n",
    "                Distort_testingResults.append(result.totalDistortion)\n",
    "                reconstructionMasks.append(result.masks)\n",
    "                \n",
    "            #Store the Average DMs for all images for a particular testing sampling percentage\n",
    "            testingResultsAverageObject.saveAverageErrorData(np.mean(MSE_testingResults), np.mean(SSIM_testingResults), np.mean(Distort_testingResults))\n",
    "            \n",
    "            all_MSE_testingResults.append(MSE_testingResults)\n",
    "            all_SSIM_testingResults.append(SSIM_testingResults)\n",
    "            all_Distort_testingResults.append(Distort_testingResults)\n",
    "            all_reconstructionMasks.append(reconstructionMasks)\n",
    "            \n",
    "            #Directory setup for individual images final save path\n",
    "            ImagesFinalSavePath = ImagesSavePath + 'StopTrainPerc_' + str(StopPercentageSLADS) + '_StopTestPerc_' + str(StopPercentageTestingSLADS) + os.path.sep\n",
    "            if os.path.exists(ImagesFinalSavePath): \n",
    "                shutil.rmtree(ImagesFinalSavePath)\n",
    "            os.makedirs(ImagesFinalSavePath)\n",
    "\n",
    "            #Obtain filenames for each of the images that were made\n",
    "            dataFileNames = glob.glob(testingFeaturesPath + \"/*\"+ImageExtension) \n",
    "            for j in range(0, len(dataFileNames)): #For each of the files\n",
    "                outputName = dataFileNames[j] #Grab the filename\n",
    "                outputName = re.sub(testingFeaturesPath, '', outputName) #Remove the directory prefix\n",
    "                shutil.move(dataFileNames[j], ImagesFinalSavePath+outputName) #Move them to an Images folder\n",
    "\n",
    "        #Plot the average DMs across the different testing sampling percentages given a particular training sampling percentage\n",
    "        testingSpecificStatisticsSavePathSuffix ='_StopTrainPerc_' + str(StopPercentageSLADS)\n",
    "        testingSpecificStatisticsSavePath = testingStatisticsSavePath + 'StopTrainPerc_' + str(StopPercentageSLADS) + os.path.sep    \n",
    "        \n",
    "        #Directory setup for specific testing statistics\n",
    "        if os.path.exists(testingSpecificStatisticsSavePath): \n",
    "            shutil.rmtree(testingSpecificStatisticsSavePath)\n",
    "        os.makedirs(testingSpecificStatisticsSavePath)      \n",
    "        \n",
    "        plotErrorData(testingSpecificStatisticsSavePath, testingSpecificStatisticsSavePathSuffix, testingResultsAverageObject, StopPercentageTestingSLADSArr.tolist(), testingPlotTitle, plotXLabel) #Plot and save the error data obtained during \n",
    "        trainTestAverageErrors.append(testingResultsAverageObject)\n",
    "        \n",
    "    #Plot the average DMS together in a single plot for all of the training sampling percentages\n",
    "    ttPlotAverageErrors(testingStatisticsSavePath, StopPercentageSLADSArr, StopPercentageTestingSLADSArr, trainTestAverageErrors)\n",
    "\n",
    "    #Plot MSE and SSIM distribution\n",
    "    names = []\n",
    "    for i in range(0, len(StopPercentageTestingSLADSArr)):\n",
    "        names.append(str(StopPercentageTestingSLADSArr[i]) + '%')\n",
    "\n",
    "    f = plt.figure(figsize=(20,8))\n",
    "    plt.hist(all_MSE_testingResults, bins=10, align='left', label=names)\n",
    "    plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='left', ncol=1)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('MSE')\n",
    "    plt.savefig(testingStatisticsSavePath + 'MSE_Distribution' + '.png')\n",
    "    \n",
    "    f = plt.figure(figsize=(20,8))\n",
    "    plt.hist(all_SSIM_testingResults, bins=10, align='left', label=names)\n",
    "    plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1, 1), loc='left', ncol=1)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('SSIM')\n",
    "    plt.savefig(testingStatisticsSavePath + 'SSIM_Distribution' + '.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "#AFTER INTENDED PROCEDURES (TRAINING/TESTING) HAVE BEEN PERFORMED\n",
    "print('\\n\\n\\n' + ('#' * int(consoleColumns)))\n",
    "print('PROGRAM COMPLETE')\n",
    "print('#' * int(consoleColumns) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#OLD ANIMATION FUNCTION, REPEATED TESTING AT INDIVIDUAL PERCENTAGES\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\n' + ('#' * int(consoleColumns)))\n",
    "print('ANIMATING MODEL')\n",
    "print(('#' * int(consoleColumns)) + '\\n')\n",
    "\n",
    "#Set initial percentages and adjustment for each step\n",
    "if not lineScanning:\n",
    "    StopPercentageTestingSLADS = 1\n",
    "    percentageAdjustment = StopPercentageTestingSLADS\n",
    "else:\n",
    "    StopPercentageTestingSLADS = (SizeImage[0]/(SizeImage[0]*SizeImage[1]))*100\n",
    "    percentageAdjustment = StopPercentageTestingSLADS\n",
    "\n",
    "    \n",
    "#Directory setup for animation images\n",
    "AnimationImagesSavePath = ImagesSavePath + 'Animation' + os.path.sep\n",
    "if os.path.exists(AnimationImagesSavePath): \n",
    "    shutil.rmtree(AnimationImagesSavePath)\n",
    "os.makedirs(AnimationImagesSavePath)\n",
    "\n",
    "#Perform testing for the images up to 50% of the total pixel count for generating an animation\n",
    "while(StopPercentageTestingSLADS <= 50):\n",
    "    StopPercentageTestingSLADS = float(StopPercentageTestingSLADS)\n",
    "    StopCondParamsObject.initialize(Beta,StoppingThrehsold,50,2,StopPercentageTestingSLADS-percentageAdjustment)\n",
    " \n",
    "    dataFileNames = glob.glob(testingDataImagesPath + \"/*\" + ImageExtension) #Obtain filenames for each testing set\n",
    "    numberTestFiles = len(testingData)\n",
    "\n",
    "    testingResultObject = []\n",
    "    for i in tqdm(range(0,numberTestFiles), desc = 'Testing Images', leave = True):\n",
    "        result = stats_parhelper(num_threads, InitialMaskObject, loadOrGenerateInitialMask(loadPathInitialMask,MaskType,InitialMaskObject,SizeImage,lineScanning), codePath, TestingImageSet, SizeImage, StopCondParamsObject, Theta, TrainingInfoObject, TestingInfoObject, Resolution, ImageType, UpdateERDParamsObject, BatchSamplingParamsObject, testingOutputName(testingFeaturesPath, dataFileNames[i], StopPercentageSLADS, StopPercentageTestingSLADS), i, ImageExtension, PlotResult, Classify, errorPlot, isRunningParallel, lineScanning, simulation, testingData[i])\n",
    "        testingResultObject.append(result)\n",
    "\n",
    "    #Create holding arrays for the results\n",
    "    mseTestingResults = []\n",
    "    ssimTestingResults = []\n",
    "    distortTestingResults = []\n",
    "\n",
    "    #Extract results from returned object\n",
    "    for result in testingResultObject: \n",
    "        mseTestingResults.append(result.mseError)\n",
    "        ssimTestingResults.append(result.ssimError)\n",
    "        distortTestingResults.append(result.totalDistortion)\n",
    "\n",
    "    #Obtain filenames for each of the images that were made\n",
    "    dataFileNames = glob.glob(testingFeaturesPath + \"/*\"+ImageExtension) \n",
    "    for j in range(0, len(dataFileNames)): #For each of the files\n",
    "        outputName = dataFileNames[j] #Grab the filename\n",
    "        outputName = re.sub(testingFeaturesPath, '', outputName) #Remove the directory prefix\n",
    "        shutil.move(dataFileNames[j], AnimationImagesSavePath+outputName) #Move them to the Animation images folder\n",
    "    if not lineScanning:\n",
    "        StopPercentageTestingSLADS += 1\n",
    "    else: #lineScanning.\n",
    "        StopPercentageTestingSLADS += percentageAdjustment\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANIMATION STUFF BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using resizeMe program, convert to jpegs into the Animation folder, then run sorting again\n",
    "#For each of the testing images create a new subfolder and move their testing results into it\n",
    "dataFileNames = glob.glob(testingDataImagesPath + \"/*\" + ImageExtension) #Obtain filenames for each set\n",
    "for i in range(0, len(dataFileNames)):\n",
    "    outputName = re.sub(testingDataImagesPath, '', dataFileNames[i])\n",
    "    outputName = re.sub('.png', '', outputName)\n",
    "    print(outputName)\n",
    "    os.mkdir(AnimationImagesSavePath + outputName)\n",
    "    animationImageFileNames = glob.glob(AnimationImagesSavePath + \"/*\" + '.jpg') \n",
    "    for j in range(0, len(animationImageFileNames)):\n",
    "        if(outputName in animationImageFileNames[j]):\n",
    "            shutil.move(animationImageFileNames[j], AnimationImagesSavePath + outputName)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "StopPercentageTestingSLADS = 0\n",
    "\n",
    "#Directory setup for animation images\n",
    "AnimationImagesSavePath = ImagesSavePath + 'Animation' + os.path.sep\n",
    "if os.path.exists(AnimationImagesSavePath): \n",
    "    shutil.rmtree(AnimationImagesSavePath)\n",
    "os.makedirs(AnimationImagesSavePath)\n",
    "\n",
    "#Perform testing for the images up to 50% of the total pixel count for generating an animation\n",
    "while(StopPercentageTestingSLADS <= 50):\n",
    "    StopPercentageTestingSLADS = float(StopPercentageTestingSLADS)\n",
    "    StopCondParamsObject.initialize(Beta,StoppingThrehsold,50,2,StopPercentageTestingSLADS)\n",
    "\n",
    "    dataFileNames = glob.glob(testingDataImagesPath + \"/*\" + ImageExtension) #Obtain filenames for each testing set\n",
    "    numberTestFiles = len(dataFileNames)\n",
    "\n",
    "    #Perform SLADS on all of the images, saving statistics of interest in parallel\n",
    "    testingResultObject = Parallel(n_jobs=num_threads)(delayed(stats_parhelper)(numberTestFiles, loadOrGenerateInitialMask(loadPathInitialMask,MaskType,InitialMaskObject,SizeImage,lineScanning), codePath, TestingImageSet, SizeImage, StopCondParamsObject, Theta, TrainingInfoObject, TestingInfoObject, Resolution, ImageType, UpdateERDParamsObject, BatchSamplingParamsObject, testingOutputName(testingFeaturesPath, dataFileNames[i], StopPercentageSLADS, StopPercentageTestingSLADS),SimulationRun, i, ImageExtension, PlotResult, Classify, dataFileNames[i], errorPlot, isRunningParallel) for i in tqdm(range(0,numberTestFiles), desc = 'Testing Images', leave = True))\n",
    "\n",
    "    #Create holding arrays for the results\n",
    "    mseTestingResults = []\n",
    "    ssimTestingResults = []\n",
    "    distortTestingResults = []\n",
    "\n",
    "    #Extract results from returned object\n",
    "    for result in testingResultObject: \n",
    "        mseTestingResults.append(result.mseError)\n",
    "        ssimTestingResults.append(result.ssimError)\n",
    "        distortTestingResults.append(result.totalDistortion)\n",
    "\n",
    "    #Obtain filenames for each of the images that were made\n",
    "    dataFileNames = glob.glob(testingFeaturesPath + \"/*\"+ImageExtension) \n",
    "    for j in range(0, len(dataFileNames)): #For each of the files\n",
    "        outputName = dataFileNames[j] #Grab the filename\n",
    "        outputName = re.sub(testingFeaturesPath, '', outputName) #Remove the directory prefix\n",
    "        shutil.move(dataFileNames[j], AnimationImagesSavePath+outputName) #Move them to the Animation images folder\n",
    "\n",
    "    StopPercentageTestingSLADS += 1 #Increase the stopping percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual segmentation comparison for masking sandstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "originalFileNames = glob.glob(testingDataImagesPath + \"/*\" + ImageExtension)\n",
    "testingDataPath = r'./manualSegmentation'\n",
    "manualMaskNames = glob.glob(testingDataPath + \"/*\" + '.png') #Obtain filenames for each set\n",
    "manualMasks = []\n",
    "\n",
    "#For each of the testing images\n",
    "for j in range(0,numberTestFiles-1):\n",
    "    SLADS_Mask = all_reconstructionMasks[0][j]\n",
    "    filename = originalFileNames[j]\n",
    "    filename = re.sub('./ResultsAndData/TestingSavedFeatures/TestingDB_1/Images/', '', filename)     \n",
    "    filename = re.sub('originalSegmentation','', filename)\n",
    "    for k in range(0,len(manualMaskNames)-1):\n",
    "        if (filename in manualMaskNames[k]):\n",
    "            manual_Mask = manualMaskNames[k]\n",
    "            manualMasks.append(manual_Mask)\n",
    "    \n",
    "\n",
    "all_MSE_results = []\n",
    "all_SSIM_results = []\n",
    "\n",
    "#For each of the percentages\n",
    "for i in range (0, len(all_reconstructionMasks)-1):\n",
    "    MSE_results = []\n",
    "    SSIM_results = []\n",
    "    \n",
    "    #For each of the testing images\n",
    "    for j in range(0,numberTestFiles-1):\n",
    "        recMask = Image.fromarray(np.asarray(all_reconstructionMasks[i][j]).reshape(SizeImage)*255)\n",
    "        recMask = PIL.ImageOps.invert(recMask)\n",
    "        manMask = Image.open(manualMasks[j]).convert('L')\n",
    "        MSE = np.mean((np.asarray(recMask).astype(\"float\") - np.asarray(manMask).astype(\"float\")) ** 2)\n",
    "        SSIM = compare_ssim(np.asarray(recMask).astype(\"float\"), np.asarray(manMask).astype(\"float\"))\n",
    "        MSE_results.append(MSE)\n",
    "        SSIM_results.append(SSIM)\n",
    "    all_MSE_results.append(MSE_results)\n",
    "    all_SSIM_results.append(SSIM_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masking MSE\n",
    "\n",
    "names = []\n",
    "for i in range(0, len(StopPercentageTestingSLADSArr)):\n",
    "    names.append(str(StopPercentageTestingSLADSArr[i]) + '%')\n",
    "\n",
    "f = plt.figure(figsize=(20,8))\n",
    "plt.hist(all_MSE_testingResults, bins=10, align='left', label=names)\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='left', ncol=1)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('MSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Masking SSIM\n",
    "f = plt.figure(figsize=(20,8))\n",
    "plt.hist(all_SSIM_testingResults, bins=10, align='left', label=names)\n",
    "plt.legend()\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='left', ncol=1)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('SSIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
